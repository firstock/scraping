{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타깃\n",
    "[naver news:공공자전거](https://search.naver.com/search.naver?&where=news&query=%EA%B3%B5%EA%B3%B5%EC%9E%90%EC%A0%84%EA%B1%B0&sm=tab_pge&sort=0&photo=0&field=0&reporter_article=&pd=0&ds=&de=&docid=&nso=so:r,p:all,a:all&mynews=0&start=1&refresh_start=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ref\n",
    "- [selenium attribute](https://stackoverflow.com/questions/30324760/how-to-get-attribute-of-element-from-selenium?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)\n",
    "- [~~selenium multiple class~~](https://stackoverflow.com/questions/21713280/find-div-element-by-multiple-class-names?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa) selenium옛버전. 이젠 contains 나 findElement는 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import os.path\n",
    "from os import rename\n",
    "from os import listdir\n",
    "\n",
    "import time\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def startWeb(numPage=1):\n",
    "    \"\"\"\n",
    "    네이버 뉴스\n",
    "    검색어: 공공자전거\n",
    "    옵션유지: 켜짐. mynews=1\n",
    "    @return driver\n",
    "    \"\"\"\n",
    "    driver= webdriver.Chrome('lib/chromedriver.exe')\n",
    "    paging= str(1+10*(numPage-1))\n",
    "    # caution: \"\\ is before &\"\n",
    "    url= \"https://search.naver.com/search.naver?&where=news\\\n",
    "    &query=%EA%B3%B5%EA%B3%B5%EC%9E%90%EC%A0%84%EA%B1%B0&sm=tab_pge\\\n",
    "    &sort=0&photo=0&field=0&reporter_article=&pd=0&ds=&de=&docid=\\\n",
    "    &nso=so:r,p:all,a:all&mynews=1&start=\"+paging+\"&refresh_start=0\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        element= WebDriverWait(driver, 10).until(\n",
    "            # is comming content?\n",
    "            EC.presence_of_element_located((By.XPATH, '//li'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print('error',e)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 언론사 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchOptPress():\n",
    "    \"\"\"\n",
    "    일간지, 뉴시스, 연합뉴스, 한국경제TV, JTBC, 시사IN\n",
    "    \"\"\"\n",
    "    #검색옵션\n",
    "    try:\n",
    "        element= WebDriverWait(driver, 10).until(\n",
    "            # is comming content?\n",
    "            EC.presence_of_element_located((By.XPATH, '//a[@id=\"_search_option_btn\"]'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print('error',e)\n",
    "    element.click()\n",
    "\n",
    "    #언론사\n",
    "    xpath1= '//li[@id=\"news_popup\"]'\n",
    "    element= driver.find_element_by_xpath(xpath1)\n",
    "    element.click()\n",
    "\n",
    "    # #전체선택 해제. '18.4.24 부로 전체선택옵션이 없어졌다 ㄷㄷ\n",
    "    # xpath2= '//input[@id=\"select_all_order\"]'\n",
    "    # element= driver.find_element_by_xpath(xpath2)\n",
    "    # element.click()\n",
    "\n",
    "    #일간지 선택\n",
    "    xpath3= '//input[@id=\"ca_p1\"]'\n",
    "    element= driver.find_element_by_xpath(xpath3)\n",
    "    element.click()\n",
    "    \n",
    "    somePress= [\"뉴시스\", \"연합뉴스\", \"한국경제TV\", \"JTBC\", \"시사IN\"]\n",
    "    for press in somePress:\n",
    "        xpath= '//label[@title=\"'+press+'\"]'\n",
    "        element= driver.find_element_by_xpath(xpath)\n",
    "        element.click()\n",
    "        \n",
    "    # 확인\n",
    "    xpathChk= '//button[@class=\"impact _submit_btn\"]'\n",
    "    element= driver.find_element_by_xpath(xpathChk)\n",
    "    element.click()\n",
    "    \n",
    "    try:\n",
    "        element= WebDriverWait(driver, 10).until(\n",
    "            # is comming content?\n",
    "            EC.presence_of_element_located((By.XPATH, '//li'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print('error',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 링크 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movePage(numPage):\n",
    "    paging= str(1+10*(numPage-1))\n",
    "    url= \"https://search.naver.com/search.naver?&where=news\\\n",
    "    &query=%EA%B3%B5%EA%B3%B5%EC%9E%90%EC%A0%84%EA%B1%B0&sm=tab_pge\\\n",
    "    &sort=0&photo=0&field=0&reporter_article=&pd=0&ds=&de=&docid=\\\n",
    "    &nso=so:r,p:all,a:all&mynews=1&start=\"+paging+\"&refresh_start=0\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        element= WebDriverWait(driver, 10).until(\n",
    "            # is comming content?\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"thumb\"]'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print('error',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveLink(listLink):\n",
    "    #caution: not '_sp_each_title' but ' _sp_each_title'\n",
    "    #amazing: there are no duplicated. why ??\n",
    "    \n",
    "    xpathLink1= '//a[@class=\" _sp_each_title\"]'\n",
    "    elements= driver.find_elements_by_xpath(xpathLink1)\n",
    "    for element in elements:\n",
    "        listLink.append(element.get_attribute(\"href\"))\n",
    "        \n",
    "    xpathLink2= '//a[@class=\"_sp_each_url _sp_each_title\"]'\n",
    "    elements= driver.find_elements_by_xpath(xpathLink2)\n",
    "    for element in elements:\n",
    "        listLink.append(element.get_attribute(\"href\"))\n",
    "        \n",
    "    return listLink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 링크의 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movePageLink(link):\n",
    "    driver.get(link)\n",
    "    try:\n",
    "        element= WebDriverWait(driver, 10).until(\n",
    "            # is coming a content?\n",
    "            EC.presence_of_element_located((By.XPATH, '//div'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print('error',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전제(낙관)\n",
    "같은 종류의 사이트라면 같은 xpath를 쓸 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkDictNewsXpath():\n",
    "    \"\"\"\n",
    "    link scraping 결과에 unique() 하고, 의뭉스런 사이트를 직접 들어가서\n",
    "    해당 언론사가 필터링한 언론사 맞는지 확인한 결과\n",
    "    \n",
    "    xpath가 틀렸다면 여기서 정정!\n",
    "    \"\"\"\n",
    "    link= ['news.khan.co', 'www.khan.co', 'h2.khan.co', 'news.kmib.co', 'www.naeil.com', 'news.donga.com', 'www.donga.com', 'realestate.donga.com', 'bizn.donga.com', 'travel.donga.com', 'studio.donga.com', 'yachtpia.donga.com', 'it.donga.com', 'www.m-i.kr', 'www.munhwa.com', 'www.seoul.co', 'ntn.seoul.co', 'stv.seoul.co', 'www.segye.com', 'local.segye.com', 'www.segyefn.com', 'economysegye.segye.com', 'fn.segye.com', 'www.asiatoday.co', 'news.chosun.com', 'biz.chosun.com', 'car.chosun.com', 'life.chosun.com', 'businessnews.chosun.com', 'news.joins.com', 'realestate.joins.com', 'www.hani.co', 'babytree.hani.co', '2korea.hani.co', 'www.hankookilbo.com', 'www.newsis.com', 'sports.news.naver', 'news.naver.com', 'app.yonhapnews.co', 'www.wowtv.co', 'www.wownet.co', 'news.wowtv.co', 'sports.wowtv.co', 'wowstar.wowtv.co', 'news.jtbc.co', 'www.sisain.co', 'www.sisainlive.com']\n",
    "    dupCnt= [3,1,1,8,1,1,3,5,1,5,2,3,1,2,2,5,1,2]\n",
    "    xpaths= ['//div[@id=\"articleBody\"]', '//div[@id=\"articleBody\"]', '//div[@class=\"articleArea\"]', '//div[@id=\"ct\"]', '//div[@class=\"content\"]', '//div[@id=\"NewsAdContent\"]', '//div[@id=\"article_content\"]', '//div[@id=\"article_txt\"]', '//div[@id=\"font\"]', '//div[@id=\"news_body_id\"]/div[@class=\"par\"]', '//div[@id=\"article_body\"]', '//div[@class=\"article-text-font-size\"]', '//article[@id=\"article-body\"]','//div[@itemprop=\"articleBody\"]', '//div[@id=\"articleWrap\"]', '//div[@id=\"divNewsContent\"]', '//div[@class=\"article_content\"]', '//div[@itemprop=\"articleBody\"]']\n",
    "    xpaths= np.array(xpaths)\n",
    "\n",
    "    xpaths_s= list(xpaths.repeat(dupCnt))\n",
    "\n",
    "    dictLink= dict(zip(link,xpaths_s))\n",
    "    return dictLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictLink= mkDictNewsXpath()\n",
    "def whatLinksXpath(link):\n",
    "    link3piece= '.'.join(link.split('/')[2].split('.')[0:3])\n",
    "    xpath= dictLink[link3piece]\n",
    "    return xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmSpecialChr(weirdStr):\n",
    "    \"\"\"\n",
    "    @param string\n",
    "    @return string. #특문제거, \\n -> ___\n",
    "    \"\"\"\n",
    "    regPattLine= '\\n'\n",
    "    res= re.sub(regPattLine,'___',weirdStr)\n",
    "    regPatt= '[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9()\": ]|[[\\u3131-\\u318E\\uAC00-\\uD7A3]]'\n",
    "    res= re.sub(regPatt,'',res)\n",
    "    res= re.sub('\\\\s+', ' ', res) # 공백 제거 해,말아? 하자. 안 하면 헬일듯\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getContent(link):\n",
    "    \"\"\"\n",
    "    @return conBodyText\n",
    "    \"\"\"\n",
    "    xpathBody= whatLinksXpath(link)\n",
    "    #print(xpathBody)\n",
    "    \n",
    "    try:\n",
    "        conBody= WebDriverWait(driver, 2).until(\n",
    "            EC.presence_of_element_located((By.XPATH, xpathBody))\n",
    "        )\n",
    "        conBodyText= rmSpecialChr(conBody.text)\n",
    "    except Exception as e:\n",
    "        print('no match xpath',e)\n",
    "        conBodyText= \"\"\n",
    "        pass\n",
    "    \n",
    "    return conBodyText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 세션 종료, 자원반납"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_성공\n",
    "1페이지에서 link 목록 따오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WELL-DONE !\n",
    "driver= startWeb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchOptPress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPage= 1\n",
    "movePage(numPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.newsis.com/view/?id=NISX20180421_0000288016&cID=10803&pID=10800',\n",
       " 'http://www.seoul.co.kr/news/newsView.php?id=20180417014003&wlog_tag3=naver',\n",
       " 'http://www.hankookilbo.com/v/0e2f312b60b84e099b87d04436fc3308',\n",
       " 'http://bizn.donga.com/realestate/3/all/20180416/89637182/2',\n",
       " 'http://news.joins.com/article/olink/22127647',\n",
       " 'http://news.joins.com/article/olink/22120203',\n",
       " 'http://news.chosun.com/site/data/html_dir/2018/04/10/2018041000149.html',\n",
       " 'http://app.yonhapnews.co.kr/YNA/Basic/SNS/r.aspx?c=AKR20180408025600004&did=1195m',\n",
       " 'http://www.asiatoday.co.kr/view.php?key=20180422010012584',\n",
       " 'http://www.asiatoday.co.kr/view.php?key=20180418010010605']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listLink= list([])\n",
    "listLink= saveLink(listLink)\n",
    "\n",
    "listLink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test _성공\n",
    "link 하나에서 뉴스 내용 퍼오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WELL-DONE !\n",
    "driver= startWeb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchOptPress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numPage= 2\n",
    "# movePage(numPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictLink= mkDictNewsXpath() # 최초 1번만 만들면 된다\n",
    "\n",
    "linkEx= 'http://www.newsis.com/view/?id=NISX20180421_0000288016&cID=10803&pID=10800'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movePageLink(linkEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//div[@itemprop=\"articleBody\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'수원뉴시스김경호 기자 수원시 무인 대여자전거수원뉴시스김경호 기자 경기 수원시가 지난해 전국 최초로 도입한 스테이션 없는 무인대여자전거가 올해 상반기 중 대폭 늘어난다 수원시는 무인대여자전거 950대를 운영하는 공유자전거 업체 모바이크(Mobike)가 상반기 안에 4050대를 추가한다고 21일 밝혔다 5월 중 1400대 6월 중 2650대를 배치할 계획이다 새롭게 배치되는 자전거는 뉴라이트 모델로 기존 자전거보다 성능이 개선됐다 자전거 무게를 6(2216) 줄였고 잠금장치 배터리 방전을 방지하기 위한 태양광 패널을 부착했다 여성아동도 쉽게 탈 수 있도록 안장 높이 조절 범위를 늘렸다 회원 가입할 때 내야 했던 보증금(5000원)은 23일부터 없애 이용자 부담을 줄인다 또 국내 모든 신용카드로 이용료를 결제할 수 있도록 결제 시스템을 개선할 계획이다 수원시는 5월부터 무인대여 자전거 주차구역 관리(자전거 정리정돈거치대 청소방치자전거 처리 등)를 민간기관에 위탁해 시민 불편을 최소화할 계획이다 자전거 이용경로를 알려주는 빅데이터를 활용해 요소요소에 자전거 주차장을 확보하고 자전거도로 정비 우선순위를 정할 예정이다 무인대여자전거 시스템은 자전거 거치대 무인 정보안내시스템 등이 필요 없다 스마트폰을 활용해 GPS가 장착된 자전거를 수원시 곳곳에 있는 자전거 주차공간에서 간편하게 대여하고 반납할 수 있다 현재 수원시에서는 공유자전거 업체인 모바이크와 오바이크(oBike)가 무인대여 자전거를 운영하고 있다 무인대여 자전거를 이용하려면 먼저 스마트폰 플레이스토어(안드로이드폰) 앱스토어(아이폰)에서 오바이크나 모바이크를 검색해 애플리케이션을 내려받아야 한다 무인자전거 앱을 활성화하면 주변에 있는 자전거 위치를 알려주는 지도가 나온다 자전거가 있는 장소를 찾아가 앱 하단 잠금 해제를 누른 후 스마트폰으로 자전거 핸들 사이에 부착된 큐알(QR)코드를 스캔하면 잠금이 해제된다 자전거를 타고 목적지까지 이동한 뒤 목적지 주변에 있는 공공자전거 주차공간(노면에 표시)이나 자전거 거치대에 세운 후 뒷바퀴 윗부분에 있는 잠금장치를 채워놓으면 된다 이용료는 30분에 300원(모바이크) 수준이다 시 관계자는 전국 최초로 운영되는 스테이션 없는 무인대여 자전거 시스템이 안착할 수 있도록 지원할 것이라며 자전거 이용이 더욱 활성화되도록 하겠다고 했다 kghnewsiscom'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents= getContent(linkEx)\n",
    "contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 할일: 링크 목록 돌려서 df 에 차곡차곡 쌓기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행- 링크얻기_완료\n",
    "링크가 필요하면 또 돌리되, 시간이 제법 걸린다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# driver= startWeb()\n",
    "# searchOptPress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data/naverNewsSomePressLinks.csv 에 저장 완료!\n",
    "# numPages= range(1,400)\n",
    "# listLink= list([])\n",
    "\n",
    "# for numPage in numPages:\n",
    "#     print(numPage)\n",
    "#     movePage(numPage)\n",
    "#     listLink= saveLink(listLink)\n",
    "\n",
    "#print(len(listLink))\n",
    "# listLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# driver.close()\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장&읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장 from Scraping\n",
    "- [dictionary to csv](https://stackoverflow.com/questions/8685809/python-writing-a-dictionary-to-a-csv-file-with-one-line-for-every-key-value?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)\n",
    "    - [writerow one line feed](https://stackoverflow.com/questions/3191528/csv-in-python-adding-an-extra-carriage-return?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # scraping 직후. 옵션외 링크가 좀 섞여있다\n",
    "# DataFrame(listLink).to_csv(\"data/naverNewsSomePressLinks.csv\", index= False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 읽기\n",
    "scraping 직후. 옵션외 링크가 좀 섞여있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linkRead= pd.read_csv(\"data/naverNewsSomePressLinks.csv\", header=None)\n",
    "\n",
    "# linkRead= list(linkRead[0])\n",
    "\n",
    "# print(len(linkRead))\n",
    "\n",
    "# linkRead[30:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 옵션 외 언론사 지우기\n",
    "133개 지움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= DataFrame(linkRead)\n",
    "\n",
    "# exceptList= ['www.kukinews.com', 'news.kukinews.com', 'www.seouland.com', 'nownews.seoul.co', 'nownewstv.seoul.co', 'www.sporbiz.co', 'www.beautyhankook.com']\n",
    "# for exLink in exceptList:\n",
    "#     df= df[df[0].map(lambda x: (exLink not in x))]\n",
    "    \n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다시 저장 though exceptList\n",
    "이게 제대로된 링크 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/naverNewsDailyPlusPressLinks.csv\", index= False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 읽기\n",
    "광고? 제거된 링크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3857, 1)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.newsis.com/view/?id=NISX20180421_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.seoul.co.kr/news/newsView.php?id=20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.hankookilbo.com/v/0e2f312b60b84e099...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  http://www.newsis.com/view/?id=NISX20180421_00...\n",
       "1  http://www.seoul.co.kr/news/newsView.php?id=20...\n",
       "2  http://www.hankookilbo.com/v/0e2f312b60b84e099..."
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkNewsDailyPlus= pd.read_csv('data/naverNewsDailyPlusPressLinks.csv',\n",
    "                               header=None)\n",
    "\n",
    "print(linkNewsDailyPlus.shape)\n",
    "print(type(linkNewsDailyPlus[0]))\n",
    "linkNewsDailyPlus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3857"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkNewsDailyPlus_list= list(linkNewsDailyPlus[0])\n",
    "len(linkNewsDailyPlus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실행- 내용얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 링크에서 각 값 따오기-> DataFrame 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3857\n"
     ]
    }
   ],
   "source": [
    "linkNewsDailyPlus= pd.read_csv('data/naverNewsDailyPlusPressLinks.csv',\n",
    "                               header=None)\n",
    "linkNewsDailyPlus_list= list(linkNewsDailyPlus[0])\n",
    "print(len(linkNewsDailyPlus_list))\n",
    "\n",
    "bodyList= list([])\n",
    "pressList3pie= list([])\n",
    "\n",
    "dictLink= mkDictNewsXpath() # 최초 1번만 만들면 된다. driver와 무관"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "no match xpath Message: \n",
      "\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "no match xpath Message: \n",
      "\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "no match xpath Message: \n",
      "\n",
      "28\n",
      "29\n",
      "no match xpath Message: \n",
      "\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "driver= startWeb()\n",
    "searchOptPress()\n",
    "\n",
    "for i, link in enumerate(linkNewsDailyPlus_list):\n",
    "    #if (0== i)| (1==i):\n",
    "    #print(link)\n",
    "    print(i)\n",
    "\n",
    "    movePageLink(link)\n",
    "    body= getContent(link)\n",
    "    bodyList.append(body)\n",
    "\n",
    "    link3piece= '.'.join(link.split('/')[2].split('.')[0:3])\n",
    "    pressList3pie.append(link3piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsData= { \n",
    "    'link3pie': pressList3pie,\n",
    "    'zbody':bodyList\n",
    "}\n",
    "dfNews= pd.DataFrame(data= newsData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfNews.to_csv('data/naverNewsContent.csv', index= False, encoding= 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dfNotice['writerP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"data/naverNewsContent.csv\", encoding= 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'title', 'writerP', 'zbody'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자열 포함된 거 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findStr(inputStr):\n",
    "    tradein= lambda x:inputStr in x\n",
    "    return df[df.zbody.map(tradein)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputStr= '음식'\n",
    "findStr(inputStr).to_csv('data/newsfind'+inputStr+'.csv', index= False, encoding= 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어느 사이트인지 판단\n",
    "18개 xpath 중에 무엇일지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linkRead= pd.read_csv(\"data/naverNewsDailyPlusPressLinks.csv\", header=None)\n",
    "# linkRead= list(linkRead[0])\n",
    "\n",
    "# pressList3piece= ['.'.join(x.split('/')[2].split('.')[0:3]) for x in linkRead]\n",
    "\n",
    "# print(Series(pressList3piece).unique())\n",
    "# print(len(Series(pressList3piece).unique()))\n",
    "# print(Series(pressList3piece).value_counts())\n",
    "\n",
    "# pressList2piece= ['.'.join(x.split('/')[2].split('.')[1:3]) for x in linkRead]\n",
    "\n",
    "# print(Series(pressList2piece).unique())\n",
    "# print(len(Series(pressList2piece).unique()))\n",
    "# print(Series(pressList2piece).value_counts())\n",
    "\n",
    "# # 18\n",
    "# # 개 언론사만 골라서했는데 27개 나옴. > 무슨무슨링크랑 회사랑 매치되는지 알아야\n",
    "# # - news.naver.com : 연합뉴스\n",
    "# # - sports.news.naver : 뉴시스\n",
    "\n",
    "# dfLinkRead= DataFrame(linkRead)\n",
    "# dfLinkEx= dfLinkRead[dfLinkRead[0].map(lambda x:'naver.com' in x)]\n",
    "# print(dfLinkEx)\n",
    "\n",
    "# # sports.news.naver  3\n",
    "# # news.naver.com 928\n",
    "# print(len(dfLinkEx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # naver 있는 게 왜이리 많은지 보기\n",
    "# dfLinkEx.to_csv(\"data/naver_in_link.csv\", index= False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### link~xpath Dictionary 만드는 코드 백업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df= pd.read_csv('data/naverNewsSomePressLinks.csv', index_col=False, header=None)\n",
    "#len(df)\n",
    "\n",
    "# ## 긁으려는 거 외 링크 지우기\n",
    "# # 133개 지움\n",
    "# exceptList= ['www.kukinews.com', 'news.kukinews.com', 'www.seouland.com', 'nownews.seoul.co', 'nownewstv.seoul.co', 'www.sporbiz.co', 'www.beautyhankook.com']\n",
    "# for exLink in exceptList:\n",
    "#     df= df[df[0].map(lambda x: (exLink not in x))]\n",
    "\n",
    "#df\n",
    "#len(df)\n",
    "#df[0].map(lambda x: (exceptList[0] in x)).sum()\n",
    "\n",
    "## dict 만들기\n",
    "# key: http빼고 사이트 앞 3어절, value: XPATH\n",
    "# link= ['news.khan.co', 'www.khan.co', 'h2.khan.co', 'news.kmib.co', 'www.naeil.com', 'news.donga.com', 'www.donga.com', 'realestate.donga.com', 'bizn.donga.com', 'travel.donga.com', 'studio.donga.com', 'yachtpia.donga.com', 'it.donga.com', 'www.m-i.kr', 'www.munhwa.com', 'www.seoul.co', 'ntn.seoul.co', 'stv.seoul.co', 'www.segye.com', 'local.segye.com', 'www.segyefn.com', 'economysegye.segye.com', 'fn.segye.com', 'www.asiatoday.co', 'news.chosun.com', 'biz.chosun.com', 'car.chosun.com', 'life.chosun.com', 'businessnews.chosun.com', 'news.joins.com', 'realestate.joins.com', 'www.hani.co', 'babytree.hani.co', '2korea.hani.co', 'www.hankookilbo.com', 'www.newsis.com', 'sports.news.naver', 'news.naver.com', 'app.yonhapnews.co', 'www.wowtv.co', 'www.wownet.co', 'news.wowtv.co', 'sports.wowtv.co', 'wowstar.wowtv.co', 'news.jtbc.co', 'www.sisain.co', 'www.sisainlive.com']\n",
    "# dupCnt= [3,1,1,8,1,1,3,5,1,5,2,3,1,2,2,5,1,2]\n",
    "# xpaths= ['//div[@id=\"articleBody\"]', '//div[@id=\"articleBody\"]', '//div[@class=\"articleArea\"]', '//div[@id=\"ct\"]', '//div[@class=\"content\"]', '//div[@id=\"NewsAdContent\"]', '//div[@id=\"article_content\"]', '//div[@id=\"article_txt\"]', '//div[@id=\"font\"]', '//div[@id=\"news_body_id\"]/div[@class=\"par\"]', '//div[@id=\"article_body\"]', '//div[@class=\"article-text-font-size\"]', '//article[@id=\"article-body\"]', '//div[@id=\"#textBody\"]', '//div[@id=\"articleWrap\"]', '//div[@id=\"divNewsContent\"]', '//div[@class=\"article_content\"]', '//div[@itemprop=\"articleBody\"]']\n",
    "# xpaths= np.array(xpaths)\n",
    "# print('xpaths렝',len(xpaths))\n",
    "# print('dupCnt렝',len(dupCnt))\n",
    "\n",
    "# xpaths_s= list(xpaths.repeat(dupCnt))\n",
    "# xpaths_s\n",
    "# print('link>> ',link)\n",
    "# print('xpaths_s>> ',xpaths_s)\n",
    "\n",
    "# dictLink= dict(zip(link,xpaths_s))\n",
    "#dictLink\n",
    "\n",
    "# ## xpath 얻기\n",
    "# sriLink= df[0].map(lambda x: '.'.join(x.split('/')[2].split('.')[0:3]))\n",
    "# #sriLink\n",
    "# #sriLink.value_counts()\n",
    "\n",
    "# ## 미리 만들어둔 list ( link ~ xpath ) ㄴㄴ\n",
    "# xpathList= list([])\n",
    "# for link in sriLink:\n",
    "#     xpathList.append(dictLink[link])\n",
    "# xpathList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
